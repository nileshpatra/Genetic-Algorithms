{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 200\n",
    "M = 0.1\n",
    "P = 500\n",
    "Dn = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20852315 0.37990322 0.81526567 0.40120023 0.83495341 0.70433796\n",
      " 0.63527978 0.71498703 0.91501536 0.86399704 0.24553359 0.68561509\n",
      " 0.69743761 0.80697528 0.33441254 0.82021852 0.91660806 0.84834148\n",
      " 0.79936442 0.21314286]\n"
     ]
    }
   ],
   "source": [
    "r = np.random.random((Dn))\n",
    "def f(x):\n",
    "    return ((x - r)**4).sum()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.388471925172265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.random((Dn))\n",
    "f(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population():\n",
    "    population = []\n",
    "    for _ in range(P):\n",
    "        population.append(np.random.uniform(-10 , 10 , (Dn)))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1 , parent2):\n",
    "    child1 = np.zeros(parent1.shape)\n",
    "    child2 = np.zeros(parent2.shape)\n",
    "    \n",
    "    dim = parent1.shape[0]//2\n",
    "    child1[:dim] = parent1[:dim]\n",
    "    child1[dim:] = parent2[dim:]\n",
    "    \n",
    "    child2[:dim] = parent2[:dim]\n",
    "    child2[dim:] = parent1[dim:]\n",
    "    \n",
    "    return child1 , child2\n",
    "\n",
    "def mutate(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        R = np.random.random()\n",
    "        if R < M:\n",
    "            x[i] = np.random.uniform(-5 , 5)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation : 0 | loss : 10230.726720281278\n",
      "Generation : 1 | loss : 7349.964386199867\n",
      "Generation : 2 | loss : 4302.691768101404\n",
      "Generation : 3 | loss : 2479.7044427200794\n",
      "Generation : 4 | loss : 883.6499338409608\n",
      "Generation : 5 | loss : 883.6499338409608\n",
      "Generation : 6 | loss : 831.2130648496155\n",
      "Generation : 7 | loss : 535.5459724919341\n",
      "Generation : 8 | loss : 514.292170616013\n",
      "Generation : 9 | loss : 236.460909545173\n",
      "Generation : 10 | loss : 236.460909545173\n",
      "Generation : 11 | loss : 236.460909545173\n",
      "Generation : 12 | loss : 156.85085290341928\n",
      "Generation : 13 | loss : 119.36818274576265\n",
      "Generation : 14 | loss : 84.63366109656452\n",
      "Generation : 15 | loss : 84.63366109656452\n",
      "Generation : 16 | loss : 62.34036021237269\n",
      "Generation : 17 | loss : 62.34036021237269\n",
      "Generation : 18 | loss : 62.34036021237269\n",
      "Generation : 19 | loss : 52.76885115002757\n",
      "Generation : 20 | loss : 52.76885115002757\n",
      "Generation : 21 | loss : 45.335131201276056\n",
      "Generation : 22 | loss : 45.335131201276056\n",
      "Generation : 23 | loss : 24.302746119982235\n",
      "Generation : 24 | loss : 24.302746119982235\n",
      "Generation : 25 | loss : 24.302746119982235\n",
      "Generation : 26 | loss : 18.96222503431378\n",
      "Generation : 27 | loss : 18.96222503431378\n",
      "Generation : 28 | loss : 18.96222503431378\n",
      "Generation : 29 | loss : 18.96222503431378\n",
      "Generation : 30 | loss : 11.49289829330084\n",
      "Generation : 31 | loss : 11.49289829330084\n",
      "Generation : 32 | loss : 11.49289829330084\n",
      "Generation : 33 | loss : 8.23897052448664\n",
      "Generation : 34 | loss : 6.222184361649981\n",
      "Generation : 35 | loss : 6.222184361649981\n",
      "Generation : 36 | loss : 3.084312612364539\n",
      "Generation : 37 | loss : 3.084312612364539\n",
      "Generation : 38 | loss : 3.084312612364539\n",
      "Generation : 39 | loss : 3.084312612364539\n",
      "Generation : 40 | loss : 3.084312612364539\n",
      "Generation : 41 | loss : 3.084312612364539\n",
      "Generation : 42 | loss : 3.084312612364539\n",
      "Generation : 43 | loss : 3.084312612364539\n",
      "Generation : 44 | loss : 3.084312612364539\n",
      "Generation : 45 | loss : 2.72623703654077\n",
      "Generation : 46 | loss : 2.612443148323907\n",
      "Generation : 47 | loss : 2.1216691778350927\n",
      "Generation : 48 | loss : 2.1216691778350927\n",
      "Generation : 49 | loss : 2.1216691778350927\n",
      "Generation : 50 | loss : 1.9419721060184412\n",
      "Generation : 51 | loss : 1.9419721060184412\n",
      "Generation : 52 | loss : 1.864219226665886\n",
      "Generation : 53 | loss : 1.864219226665886\n",
      "Generation : 54 | loss : 1.6771110060459056\n",
      "Generation : 55 | loss : 1.621922894798943\n",
      "Generation : 56 | loss : 1.621922894798943\n",
      "Generation : 57 | loss : 1.612920443606273\n",
      "Generation : 58 | loss : 1.3722100422149186\n",
      "Generation : 59 | loss : 1.3722100422149186\n",
      "Generation : 60 | loss : 1.3092546937374396\n",
      "Generation : 61 | loss : 1.2479794040796865\n",
      "Generation : 62 | loss : 1.2479794040796865\n",
      "Generation : 63 | loss : 1.0364203870603332\n",
      "Generation : 64 | loss : 0.6640534491212327\n",
      "Generation : 65 | loss : 0.6640534491212327\n",
      "Generation : 66 | loss : 0.6640534491212327\n",
      "Generation : 67 | loss : 0.6640534491212327\n",
      "Generation : 68 | loss : 0.6640534491212327\n",
      "Generation : 69 | loss : 0.6640534491212327\n",
      "Generation : 70 | loss : 0.6640534491212327\n",
      "Generation : 71 | loss : 0.5548318658123255\n",
      "Generation : 72 | loss : 0.5548318658123255\n",
      "Generation : 73 | loss : 0.35892216973944424\n",
      "Generation : 74 | loss : 0.35892216973944424\n",
      "Generation : 75 | loss : 0.300737211016734\n",
      "Generation : 76 | loss : 0.300737211016734\n",
      "Generation : 77 | loss : 0.300737211016734\n",
      "Generation : 78 | loss : 0.29570857886760304\n",
      "Generation : 79 | loss : 0.29570857886760304\n",
      "Generation : 80 | loss : 0.29570857886760304\n",
      "Generation : 81 | loss : 0.2766987150483916\n",
      "Generation : 82 | loss : 0.1707528804035641\n",
      "Generation : 83 | loss : 0.1707528804035641\n",
      "Generation : 84 | loss : 0.15678638075345483\n",
      "Generation : 85 | loss : 0.15678638075345483\n",
      "Generation : 86 | loss : 0.15678638075345483\n",
      "Generation : 87 | loss : 0.13055163230814681\n",
      "Generation : 88 | loss : 0.1076969688726478\n",
      "Generation : 89 | loss : 0.1076969688726478\n",
      "Generation : 90 | loss : 0.1076969688726478\n",
      "Generation : 91 | loss : 0.1076969688726478\n",
      "Generation : 92 | loss : 0.1076969688726478\n",
      "Generation : 93 | loss : 0.1076969688726478\n",
      "Generation : 94 | loss : 0.10552809754757532\n",
      "Generation : 95 | loss : 0.09948078650404231\n",
      "Generation : 96 | loss : 0.09948078650404231\n",
      "Generation : 97 | loss : 0.08788231920397517\n",
      "Generation : 98 | loss : 0.07351875898013346\n",
      "Generation : 99 | loss : 0.07351875898013346\n",
      "Generation : 100 | loss : 0.07351875898013346\n",
      "Generation : 101 | loss : 0.07351875898013346\n",
      "Generation : 102 | loss : 0.07351875898013346\n",
      "Generation : 103 | loss : 0.07351875898013346\n",
      "Generation : 104 | loss : 0.07085190550708348\n",
      "Generation : 105 | loss : 0.07085190550708348\n",
      "Generation : 106 | loss : 0.06008825308403398\n",
      "Generation : 107 | loss : 0.06008825308403398\n",
      "Generation : 108 | loss : 0.06008825308403398\n",
      "Generation : 109 | loss : 0.06008825308403398\n",
      "Generation : 110 | loss : 0.06008825308403398\n",
      "Generation : 111 | loss : 0.05618137542529528\n",
      "Generation : 112 | loss : 0.05618137542529528\n",
      "Generation : 113 | loss : 0.05618137542529528\n",
      "Generation : 114 | loss : 0.05618137542529528\n",
      "Generation : 115 | loss : 0.05618137542529528\n",
      "Generation : 116 | loss : 0.05618137542529528\n",
      "Generation : 117 | loss : 0.04982865527585489\n",
      "Generation : 118 | loss : 0.04982865527585489\n",
      "Generation : 119 | loss : 0.04714348858171737\n",
      "Generation : 120 | loss : 0.04714348858171737\n",
      "Generation : 121 | loss : 0.04714348858171737\n",
      "Generation : 122 | loss : 0.039274497078029796\n",
      "Generation : 123 | loss : 0.039274497078029796\n",
      "Generation : 124 | loss : 0.039274497078029796\n",
      "Generation : 125 | loss : 0.039274497078029796\n",
      "Generation : 126 | loss : 0.039274497078029796\n",
      "Generation : 127 | loss : 0.039274497078029796\n",
      "Generation : 128 | loss : 0.03789620661896544\n",
      "Generation : 129 | loss : 0.03789620661896544\n",
      "Generation : 130 | loss : 0.03307018275416333\n",
      "Generation : 131 | loss : 0.03307018275416333\n",
      "Generation : 132 | loss : 0.03307018275416333\n",
      "Generation : 133 | loss : 0.03307018275416333\n",
      "Generation : 134 | loss : 0.03307018275416333\n",
      "Generation : 135 | loss : 0.027930806654659517\n",
      "Generation : 136 | loss : 0.017014125989116842\n",
      "Generation : 137 | loss : 0.017014125989116842\n",
      "Generation : 138 | loss : 0.017014125989116842\n",
      "Generation : 139 | loss : 0.01575250672822185\n",
      "Generation : 140 | loss : 0.01575250672822185\n",
      "Generation : 141 | loss : 0.01575250672822185\n",
      "Generation : 142 | loss : 0.012714726890056361\n",
      "Generation : 143 | loss : 0.012714726890056361\n",
      "Generation : 144 | loss : 0.012714726890056361\n",
      "Generation : 145 | loss : 0.012714726890056361\n",
      "Generation : 146 | loss : 0.01226427530336207\n",
      "Generation : 147 | loss : 0.01226427530336207\n",
      "Generation : 148 | loss : 0.011640417883286817\n",
      "Generation : 149 | loss : 0.008763046271539185\n",
      "Generation : 150 | loss : 0.008763046271539185\n",
      "Generation : 151 | loss : 0.008763046271539185\n",
      "Generation : 152 | loss : 0.008763046271539185\n",
      "Generation : 153 | loss : 0.008763046271539185\n",
      "Generation : 154 | loss : 0.008763046271539185\n",
      "Generation : 155 | loss : 0.007237440113617746\n",
      "Generation : 156 | loss : 0.007237440113617746\n",
      "Generation : 157 | loss : 0.007237440113617746\n",
      "Generation : 158 | loss : 0.007237440113617746\n",
      "Generation : 159 | loss : 0.007237440113617746\n",
      "Generation : 160 | loss : 0.007035495713300217\n",
      "Generation : 161 | loss : 0.007035495713300217\n",
      "Generation : 162 | loss : 0.007035495713300217\n",
      "Generation : 163 | loss : 0.007035495713300217\n",
      "Generation : 164 | loss : 0.007035495713300217\n",
      "Generation : 165 | loss : 0.005790265241821075\n",
      "Generation : 166 | loss : 0.005790265241821075\n",
      "Generation : 167 | loss : 0.005790265241821075\n",
      "Generation : 168 | loss : 0.005790265241821075\n",
      "Generation : 169 | loss : 0.0057901639310395945\n",
      "Generation : 170 | loss : 0.0057901639310395945\n",
      "Generation : 171 | loss : 0.004493274983279344\n",
      "Generation : 172 | loss : 0.004264557773118152\n",
      "Generation : 173 | loss : 0.004264557773118152\n",
      "Generation : 174 | loss : 0.004264557773118152\n",
      "Generation : 175 | loss : 0.004264557773118152\n",
      "Generation : 176 | loss : 0.004264557773118152\n",
      "Generation : 177 | loss : 0.004264557773118152\n",
      "Generation : 178 | loss : 0.00414618422373505\n",
      "Generation : 179 | loss : 0.001958767906819427\n",
      "Generation : 180 | loss : 0.001958767906819427\n",
      "Generation : 181 | loss : 0.001958767906819427\n",
      "Generation : 182 | loss : 0.001958767906819427\n",
      "Generation : 183 | loss : 0.001958767906819427\n",
      "Generation : 184 | loss : 0.001730050696658236\n",
      "Generation : 185 | loss : 0.001730050696658236\n",
      "Generation : 186 | loss : 0.001730050696658236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation : 187 | loss : 0.0016353129270508726\n",
      "Generation : 188 | loss : 0.0016353129270508726\n",
      "Generation : 189 | loss : 0.0016353129270508726\n",
      "Generation : 190 | loss : 0.0016353129270508726\n",
      "Generation : 191 | loss : 0.001551531722143191\n",
      "Generation : 192 | loss : 0.0011686942449794346\n",
      "Generation : 193 | loss : 0.0011686942449794346\n",
      "Generation : 194 | loss : 0.0011686942449794346\n",
      "Generation : 195 | loss : 0.0011686942449794346\n",
      "Generation : 196 | loss : 0.0011686942449794346\n",
      "Generation : 197 | loss : 0.0011686942449794346\n",
      "Generation : 198 | loss : 0.0011686942449794346\n",
      "Generation : 199 | loss : 0.0009399770348182444\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "pop = generate_population()\n",
    "for epoch in range(G):\n",
    "    pop = sorted(pop, key=lambda z: f(z))\n",
    "    print(\"Generation : {} | loss : {}\".format(epoch , f(pop[0])))\n",
    "    loss.append(f(pop[0]))\n",
    "    \n",
    "    temp = []\n",
    "    while len(temp) < P:\n",
    "        parent1 , parent2 = random.sample(pop[:int(P/2)],2)\n",
    "        c1 , c2 = crossover(parent1 , parent2)\n",
    "        c1 , c2 = mutate(c1) , mutate(c2)\n",
    "        temp.append(c1)\n",
    "        temp.append(c2)\n",
    "        \n",
    "    comb = temp+pop\n",
    "    pop = sorted(comb, key=lambda z: f(z))[:P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f74a684b4a8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.22063736, 0.46168877, 0.87790578, 0.53710908, 0.8047196 ,\n",
       "        0.67370509, 0.58418035, 0.746163  , 0.87845283, 0.82458159,\n",
       "        0.15583464, 0.68753042, 0.70271312, 0.72531012, 0.26750223,\n",
       "        0.69329349, 1.02091544, 0.84190441, 0.78502348, 0.14824015]),\n",
       " array([0.20852315, 0.37990322, 0.81526567, 0.40120023, 0.83495341,\n",
       "        0.70433796, 0.63527978, 0.71498703, 0.91501536, 0.86399704,\n",
       "        0.24553359, 0.68561509, 0.69743761, 0.80697528, 0.33441254,\n",
       "        0.82021852, 0.91660806, 0.84834148, 0.79936442, 0.21314286]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop[0] , r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
